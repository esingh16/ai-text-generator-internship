# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZAoMaxqzaAoL91aPerWW59nheq6TUoRg
"""

import streamlit as st
from transformers import pipeline, set_seed

# Set a fixed seed for reproducibility in text generation (optional but good practice)
set_seed(42)

# --- Load Models (Cached for efficiency) ---
# Use st.cache_resource to load the models once and reuse them
@st.cache_resource
def load_sentiment_model():
    # A robust model for general sentiment analysis (e.g., 'distilbert-base-uncased-finetuned-sst-2-english')
    # For speed, we'll use a very common and efficient one.
    return pipeline("sentiment-analysis")

@st.cache_resource
def load_generator_model():
    # Use a fast and efficient text generation model (e.g., 'gpt2' or 'distilgpt2')
    return pipeline("text-generation", model="distilgpt2")

sentiment_analyzer = load_sentiment_model()
text_generator = load_generator_model()


# --- Main Application Logic ---

def get_sentiment(text):
    """Classifies the sentiment of the input text."""
    # The pipeline returns a list of dicts: [{'label': 'POSITIVE', 'score': 0.999...}]
    result = sentiment_analyzer(text)[0]
    # Standardize to 'positive', 'negative', or 'neutral'
    # Since the default model only gives POSITIVE/NEGATIVE, we handle that.
    label = result['label'].lower()

    # Simple rule for 'neutral' classification if the default model is used
    if result['score'] < 0.8:  # If confidence is low, consider it neutral
        return 'neutral'
    return label


def generate_text(prompt, sentiment, max_length=150, num_return_sequences=1):
    """Generates text based on the prompt and the detected sentiment."""

    # 1. Prepare a control prompt to inject the detected sentiment (Prompt Engineering)
    sentiment_prefix = f"The overall mood should be **{sentiment}**. "
    full_prompt = sentiment_prefix + prompt

    # 2. Generate the text
    generated_list = text_generator(
        full_prompt,
        max_length=max_length,
        num_return_sequences=num_return_sequences,
        do_sample=True,  # Enables sampling for more creative text
        temperature=0.9, # Higher temp for creativity
        pad_token_id=text_generator.tokenizer.eos_token_id # Prevents warnings
    )

    # The generated text includes the prompt. We extract the full generated part.
    # The first element's 'generated_text' is the full output.
    full_output = generated_list[0]['generated_text']

    # Attempt to clean up by removing the generated prefix and only returning the essay/paragraph
    # This is often tricky, but necessary for a cleaner output

    # Find the end of the injected prefix and return the rest
    if sentiment_prefix in full_output:
        # Get everything after the injected prefix
        final_text = full_output.split(sentiment_prefix, 1)[-1].strip()
        # Optionally, remove the original user prompt if it was included directly after the prefix
        if prompt in final_text:
             return final_text.split(prompt, 1)[-1].strip()
        return final_text

    # Fallback return of the full generated text
    return full_output


# --- Streamlit Frontend UI ---

st.title("ðŸ¤– AI Sentiment-Aligned Text Generator")
st.markdown("Enter a topic or a seed sentence. The AI will first detect the sentiment and then generate a paragraph or essay matching that feeling.")
st.markdown("---")


# 1. User Input Area
user_prompt = st.text_area(
    "ðŸ“ Enter your prompt (e.g., 'The future of space travel is exciting' or 'Write about climate change'):",
    "The new advancements in AI are truly astonishing.",
    height=150
)

# 2. Optional Enhancements (User Selection)
st.sidebar.header("âš™ï¸ Generation Settings")
# Manual sentiment selection
manual_sentiment = st.sidebar.radio(
    "Override Detected Sentiment (Optional):",
    ('Auto-Detect', 'positive', 'negative', 'neutral')
)

# Length adjustment
max_len = st.sidebar.slider(
    "Max Output Length (Tokens):",
    min_value=50,
    max_value=300,
    value=150,
    step=25
)


# 3. Execution Button
if st.button("âœ¨ Generate Text"):
    if not user_prompt.strip():
        st.error("Please enter a prompt to generate text.")
    else:
        # Status message
        with st.spinner('Analyzing sentiment and generating text...'):

            # --- Sentiment Detection ---
            if manual_sentiment == 'Auto-Detect':
                detected_sentiment = get_sentiment(user_prompt)
            else:
                detected_sentiment = manual_sentiment

            st.subheader(f"âœ… Detected/Selected Sentiment: **{detected_sentiment.upper()}**")
            st.markdown("---")

            # --- Text Generation ---
            generated_text = generate_text(
                user_prompt,
                detected_sentiment,
                max_length=max_len
            )

            # --- Output Display ---
            st.subheader("Generated Text")
            st.success(generated_text)

            # Display metadata for clarity
            st.info(f"**Seed Prompt:** {user_prompt}\n\n**Generation Model:** DistilGPT-2")

!pip install streamlit